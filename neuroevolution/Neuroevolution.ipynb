{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xscsSfa9o7Pr"
      },
      "source": [
        "<img src=\"https://github.com/d9w/evolution/raw/master/imgs/logo.png\" width=\"20%\" align=\"right\" style=\"margin:0px 20px\">\n",
        "\n",
        "\n",
        "# Evolutionary Algorithms\n",
        "\n",
        "## Evolving Neural Networks with ES\n",
        "\n",
        "<a rel=\"license\" href=\"http://creativecommons.org/licenses/by-sa/4.0/\"><img alt=\"Creative Commons License\" align=\"left\" src=\"https://i.creativecommons.org/l/by-sa/4.0/80x15.png\" /></a>&nbsp;| Dennis G. Wilson, Yuri Lavinas, Paul Templier | <a href=\"https://d9w.github.io/evolution/\">https://d9w.github.io/evolution/</a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rMNoJjbeo7Ps"
      },
      "source": [
        "In order to visualize the environment in this notebook, you will need to install the following:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FhyloBHDo7Pt"
      },
      "outputs": [],
      "source": [
        "!apt-get install -y xvfb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wziNRz5to7Pt"
      },
      "outputs": [],
      "source": [
        "!pip install cma swig"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " !pip install pyvirtualdisplay gymnasium[box2d]"
      ],
      "metadata": {
        "id": "uj99QPfPq083"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mYHEMwqCo7Pt"
      },
      "outputs": [],
      "source": [
        "#!pip install torch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6U8g1JLlo7Pu"
      },
      "source": [
        "# <a name=\"neuroevolution\">3.</a> ES for Neuroevolution"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-kFo__Oko7Pu"
      },
      "source": [
        "Evolutionary strategies are intended for continuous optimization and can easily be applied to the optimization of neural network parameters, or *neuroevolution*."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ABKY7svxo7Pu"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.multiprocessing as mp\n",
        "import numpy as np\n",
        "import gymnasium as gym\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dtG-vrkao7Pv"
      },
      "outputs": [],
      "source": [
        "class NeuralNetwork(nn.Module):\n",
        "\n",
        "    def __init__(self, input_shape, n_actions):\n",
        "        super(NeuralNetwork, self).__init__()\n",
        "        self.l1 = nn.Linear(input_shape, 32)\n",
        "        self.l2 = nn.Linear(32, 32)\n",
        "        self.lout = nn.Linear(32, n_actions)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.l1(x.float()))\n",
        "        x = F.relu(self.l2(x))\n",
        "        return self.lout(x)\n",
        "\n",
        "    def get_params(self):\n",
        "        p = np.empty((0,))\n",
        "        for n in self.parameters():\n",
        "            p = np.append(p, n.flatten().cpu().detach().numpy())\n",
        "        return p\n",
        "\n",
        "    def set_params(self, x):\n",
        "        start = 0\n",
        "        for p in self.parameters():\n",
        "            e = start + np.prod(p.shape)\n",
        "            p.data = torch.FloatTensor(x[start:e]).reshape(p.shape)\n",
        "            start = e"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ys8WPRh7o7Pv"
      },
      "source": [
        "We'll add some visualization functionality to have the environment render directly in the notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OdK60705o7Pv"
      },
      "outputs": [],
      "source": [
        "from pyvirtualdisplay import Display\n",
        "from IPython import display\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "pydisplay = Display(visible=0, size=(1400, 900))\n",
        "pydisplay.start()\n",
        "plt.ion();"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8DdM7Fwmo7Pw"
      },
      "source": [
        "Following the framework of evolutionary policy search, we will optimize a neural network representing a policy and maximize the total reward over a single episode using this policy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ef6Vc1g6o7Pw"
      },
      "outputs": [],
      "source": [
        "def evaluate(ann, env, visul=True):\n",
        "    obs, info = env.reset(seed=0)\n",
        "\n",
        "    # Create the figure and axis only once before starting\n",
        "    if visul:\n",
        "        plt.figure(figsize=(8, 6))\n",
        "        img = plt.imshow(env.render())\n",
        "        plt.axis('off')\n",
        "        plt.tight_layout()\n",
        "\n",
        "    total_reward = 0\n",
        "    while True:\n",
        "        # Output of the neural net\n",
        "        net_output = ann(torch.tensor(obs))\n",
        "        # the action is the value clipped returned by the nn\n",
        "        action = net_output.data.cpu().numpy().argmax()\n",
        "        obs, reward, done, truncated, info = env.step(action)\n",
        "        total_reward += reward\n",
        "\n",
        "        if visul:\n",
        "            img.set_data(env.render())\n",
        "            display.display(plt.gcf())\n",
        "            display.clear_output(wait=True)\n",
        "            # Small sleep to allow rendering to complete properly\n",
        "            time.sleep(0.01)\n",
        "\n",
        "        if done:\n",
        "            break\n",
        "\n",
        "    if visul:\n",
        "        plt.close()\n",
        "\n",
        "    return total_reward"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "59T71pJpo7Pw"
      },
      "source": [
        "We've configured this for discrete action spaces. We can see a random neural network on different environments like `CartPole-v0`, `MountainCar-v0`, and `LunarLander-v2`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zCIn7l4zo7Pw"
      },
      "outputs": [],
      "source": [
        "env = gym.make('LunarLander-v3', render_mode='rgb_array')\n",
        "ann = NeuralNetwork(env.observation_space.shape[0], env.action_space.n)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yXo6-crpo7Pw"
      },
      "outputs": [],
      "source": [
        "evaluate(ann, env, visul=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oaAbf0XSo7Pw"
      },
      "source": [
        "In order to evolve the parameters of this neural network, we will modify the parameters of the network using `set_params` with the genes of the new individual. In the evolutionary literature, this is referred to as a *direct encoding* as the neural network parameters are directly encoded in the genome."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hFm6TDqwo7Px"
      },
      "outputs": [],
      "source": [
        "def fitness(x, ann, env, visul=False):\n",
        "    ann.set_params(x)\n",
        "    return -evaluate(ann, env, visul=visul)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "drvQzAUJo7Px"
      },
      "outputs": [],
      "source": [
        "p = ann.get_params()\n",
        "np.shape(p)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E9W5141po7Px"
      },
      "source": [
        "We can first observe a random individual $x$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pf7JsCeMo7Px"
      },
      "outputs": [],
      "source": [
        "x = np.random.rand(len(p))\n",
        "-fitness(x, ann, env, visul=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qg-zwRo2o7Px"
      },
      "source": [
        "Let's try optimizing the policy using the simple $(\\mu, \\lambda)$ ES we proposed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ni-v3IjDo7Px"
      },
      "outputs": [],
      "source": [
        "def mu_lambda(x, fitness, gens=200, lam=10, alpha=0.2, verbose=False):\n",
        "    x_best = x\n",
        "    f_best = fitness(x)\n",
        "    fits = np.zeros(gens)\n",
        "    for g in range(gens):\n",
        "        N = np.random.normal(size=(lam, len(x)))\n",
        "        F = np.zeros(lam)\n",
        "        for i in range(lam):\n",
        "            ind = x + N[i, :]\n",
        "            F[i] = fitness(ind)\n",
        "            if F[i] < f_best:\n",
        "                f_best = F[i]\n",
        "                x_best = ind\n",
        "                if verbose:\n",
        "                    print(g, \" \", f_best)\n",
        "        fits[g] = f_best\n",
        "        mu_f = np.mean(F)\n",
        "        std_f = np.std(F)\n",
        "        A = F\n",
        "        if std_f != 0:\n",
        "            A = (F - mu_f) / std_f\n",
        "        x = x - alpha * np.dot(A, N) / lam\n",
        "    return fits, x_best"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r2IQPQuoo7Px"
      },
      "outputs": [],
      "source": [
        "np.random.seed(654)\n",
        "env = gym.make('LunarLander-v3', render_mode='rgb_array')\n",
        "ann = NeuralNetwork(env.observation_space.shape[0], env.action_space.n)\n",
        "x = np.random.randn(len(ann.get_params()))\n",
        "f = lambda x : fitness(x, ann, env)\n",
        "fits, x = mu_lambda(x, f, gens=10, lam=10, alpha=0.1, verbose=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q4ra9XbHo7Px"
      },
      "outputs": [],
      "source": [
        "fits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X8JX8zS4o7Py"
      },
      "outputs": [],
      "source": [
        "plt.plot(fits);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YhdkKzUvo7Py"
      },
      "outputs": [],
      "source": [
        "-fitness(x, ann, env, visul=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eXuGnNQvo7Py"
      },
      "source": [
        "# CMA-ES for Neuroevolution"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5TPByeGlo7Py"
      },
      "source": [
        "We will now use CMA-ES for the Lunar Lander problem"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OYPW3MpQo7Py"
      },
      "outputs": [],
      "source": [
        "import cma\n",
        "np.random.seed(123)\n",
        "env = gym.make('LunarLander-v3', render_mode='rgb_array')\n",
        "ann = NeuralNetwork(env.observation_space.shape[0], env.action_space.n)\n",
        "es = cma.CMAEvolutionStrategy(len(ann.get_params()) * [0], 0.1, {'seed': 123})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sF-mpwrXo7Py"
      },
      "outputs": [],
      "source": [
        "for i in range(20):\n",
        "    solutions = np.array(es.ask())\n",
        "    fits = [fitness(x, ann, env) for x in solutions]\n",
        "    es.tell(solutions, fits)\n",
        "    es.disp()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TOikg1p5o7Py"
      },
      "outputs": [],
      "source": [
        "x = es.result[0]\n",
        "-fitness(x, ann, env, visul=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Qx8B9Qxo7Py"
      },
      "source": [
        "The results on LunarLander clearly show the benefits of CMA-ES; we have found a reasonable policy in a small number of generations. Applying CMA-ES to larger neural networks remains an open challenge, however, due to the vast number of parameters in ANNs. Specifically, CMA-ES calculates the covariance of all parameters, which is $O(n^2)$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rHn4GUUfo7Py"
      },
      "outputs": [],
      "source": [
        "np.shape(es.sm.C)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MvTCkjkKo7Pz"
      },
      "source": [
        "<div class=\"alert alert-success\">\n",
        "    <h3>Exercise 1</h3>\n",
        "    \n",
        "The network used has 2 layers of 32 neurons each. Try changing this and noticing the impact on the number of total parameters for CMA-ES. How large of a network can CMA-ES optimize?\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kdzW9_jko7Pz"
      },
      "source": [
        "<div class=\"alert alert-success\">\n",
        "    <h3>Exercise 2</h3>\n",
        "    \n",
        "Compare the $(1+\\lambda)$ ES, $(\\mu,\\lambda)$ ES, and CMA-ES algorithms on Lunar Lander. Is one significantly better than the others, consistently across different initializations?\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eAHHt4Ldo7Pz"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "@webio": {
      "lastCommId": null,
      "lastKernelId": null
    },
    "celltoolbar": "Slideshow",
    "kernelspec": {
      "display_name": "evolutionaryClass",
      "language": "python",
      "name": "evolutionaryclass"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}